"""
Demo: Enhanced Security Analysis

Shows before/after comparison of side effect profile property extraction.
Run with: python demo_security_enhancement.py
"""

from src.foundational_properties import FoundationalProperties
import json


def demo_pure_function():
    """Demo on pure function (no side effects)"""
    print("="*60)
    print("DEMO 1: Pure Function (No Side Effects)")
    print("="*60)
    
    code = """
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
"""
    
    props = FoundationalProperties()
    result = props.extract_all_properties(code)
    profile = result["side_effect_profile"]
    
    print("\nðŸ“Š BASELINE (AST-only):")
    print(f"  - Has print: {profile['has_print']}")
    print(f"  - Has file I/O: {profile['has_file_io']}")
    print(f"  - Is pure: {profile['is_pure']}")
    
    if 'security_score' in profile:
        print("\nâœ¨ ENHANCED (bandit):")
        print(f"  - Security score: {profile['security_score']:.2f}/1.00")
        print(f"  - Purity level: {profile['purity_level']}")
        print(f"  - I/O operations: {len(profile['io_operations'])}")
        print(f"  - Network calls: {len(profile['network_calls'])}")
        print(f"  - System calls: {len(profile['system_calls'])}")
        print(f"  - Unsafe operations: {len(profile['unsafe_operations'])}")
        print(f"  - Security risks: {len(profile['security_risks'])}")
    else:
        print("\nâš ï¸  bandit not available (install with: pip install bandit)")


def demo_file_io():
    """Demo on file I/O operations"""
    print("\n" + "="*60)
    print("DEMO 2: File I/O Detection")
    print("="*60)
    
    code = """
def read_config(filename):
    with open(filename, 'r') as f:
        return f.read()
"""
    
    props = FoundationalProperties()
    result = props.extract_all_properties(code)
    profile = result["side_effect_profile"]
    
    print("\nðŸ“Š BASELINE (AST-only):")
    print(f"  - Has file I/O: {profile['has_file_io']}")
    print(f"  - Is pure: {profile['is_pure']}")
    
    if 'io_operations' in profile:
        print("\nâœ¨ ENHANCED (bandit):")
        print(f"  - I/O operations detected: {len(profile['io_operations'])}")
        if profile['io_operations']:
            for op in profile['io_operations']:
                print(f"      â€¢ Line {op['line']}: {op['message']}")
        print(f"  - Security score: {profile['security_score']:.2f}/1.00")


def demo_unsafe_operations():
    """Demo on unsafe operations (eval, exec)"""
    print("\n" + "="*60)
    print("DEMO 3: Unsafe Operation Detection")
    print("="*60)
    
    code = """
def evaluate_expression(expr):
    result = eval(expr)  # Dangerous!
    return result
"""
    
    props = FoundationalProperties()
    result = props.extract_all_properties(code)
    profile = result["side_effect_profile"]
    
    print("\nðŸ“Š BASELINE (AST-only):")
    print(f"  - Can't detect eval() as unsafe âŒ")
    print(f"  - Is pure: {profile['is_pure']}")
    
    if 'unsafe_operations' in profile:
        print("\nâœ¨ ENHANCED (bandit):")
        print(f"  - Unsafe operations: {len(profile['unsafe_operations'])}")
        if profile['unsafe_operations']:
            for op in profile['unsafe_operations']:
                print(f"      â€¢ Line {op['line']}: {op['message']}")
                print(f"        Severity: {op['severity']}")
        print(f"  - Security score: {profile['security_score']:.2f}/1.00")
        print(f"  - Purity level: {profile['purity_level']}")
        
        print("\n  ðŸ’¡ Research Impact:")
        print("  Baseline: Misses eval() completely")
        print("  Enhanced: Detects unsafe code execution immediately!")


def demo_system_calls():
    """Demo on system calls (subprocess)"""
    print("\n" + "="*60)
    print("DEMO 4: System Call Detection")
    print("="*60)
    
    code = """
import subprocess

def run_command(cmd):
    subprocess.call(cmd, shell=True)  # Shell injection risk!
    return True
"""
    
    props = FoundationalProperties()
    result = props.extract_all_properties(code)
    profile = result["side_effect_profile"]
    
    print("\nðŸ“Š BASELINE (AST-only):")
    print(f"  - Limited detection of system calls âš ï¸")
    
    if 'system_calls' in profile:
        print("\nâœ¨ ENHANCED (bandit):")
        print(f"  - System calls detected: {len(profile['system_calls'])}")
        if profile['system_calls']:
            for call in profile['system_calls']:
                print(f"      â€¢ Line {call['line']}: {call['message']}")
                print(f"        Severity: {call['severity']}")
        
        print(f"\n  Security risks: {len(profile['security_risks'])}")
        if profile['security_risks']:
            for risk in profile['security_risks'][:3]:  # Show first 3
                print(f"      â€¢ {risk['message']}")
        
        print(f"\n  - Security score: {profile['security_score']:.2f}/1.00")
        print(f"  - Purity level: {profile['purity_level']}")


def demo_comparison():
    """Compare safe vs unsafe code"""
    print("\n" + "="*60)
    print("DEMO 5: Safe vs Unsafe Code Comparison")
    print("="*60)
    
    safe_code = """
def calculate_sum(numbers):
    return sum(numbers)
"""
    
    unsafe_code = """
import os

def execute_user_command(cmd):
    os.system(cmd)  # Multiple security issues!
    return True
"""
    
    props = FoundationalProperties()
    
    print("\nðŸ“Š Safe Code:")
    safe_result = props.extract_all_properties(safe_code)
    safe_profile = safe_result["side_effect_profile"]
    print(f"  - Is pure (baseline): {safe_profile['is_pure']}")
    
    print("\nðŸ“Š Unsafe Code:")
    unsafe_result = props.extract_all_properties(unsafe_code)
    unsafe_profile = unsafe_result["side_effect_profile"]
    print(f"  - Is pure (baseline): {unsafe_profile['is_pure']}")
    
    if 'security_score' in safe_profile and 'security_score' in unsafe_profile:
        print("\nâœ¨ ENHANCED Comparison:")
        print(f"  Safe code:")
        print(f"    â€¢ Security score: {safe_profile['security_score']:.2f}/1.00")
        print(f"    â€¢ Purity level: {safe_profile['purity_level']}")
        print(f"    â€¢ Total issues: {safe_profile.get('total_issues', 0)}")
        
        print(f"\n  Unsafe code:")
        print(f"    â€¢ Security score: {unsafe_profile['security_score']:.2f}/1.00")
        print(f"    â€¢ Purity level: {unsafe_profile['purity_level']}")
        print(f"    â€¢ System calls: {len(unsafe_profile['system_calls'])}")
        print(f"    â€¢ Total issues: {len(unsafe_profile['security_risks']) + len(unsafe_profile['system_calls'])}")
        
        print("\n  ðŸ”¬ Research Insight:")
        print(f"  Security score difference: {safe_profile['security_score'] - unsafe_profile['security_score']:.2f}")
        print("  Can now QUANTIFY code safety!")
        print("  Stronger equivalence: Same security profile = truly equivalent")


if __name__ == "__main__":
    print("\nðŸ§ª Enhanced Security Analysis Demo")
    print("Showing integration of bandit with AST baseline\n")
    
    demo_pure_function()
    demo_file_io()
    demo_unsafe_operations()
    demo_system_calls()
    demo_comparison()
    
    print("\n" + "="*60)
    print("âœ… Step 4 Complete: side_effect_profile property enhanced!")
    print("="*60)
    print("\nKey achievements:")
    print("  âœ“ Backward compatible (baseline always present)")
    print("  âœ“ Graceful degradation (works without bandit)")
    print("  âœ“ Security vulnerability detection (CVE-level)")
    print("  âœ“ Comprehensive side effect profiling (I/O, network, system)")
    print("  âœ“ Security scoring (quantifiable safety metric)")
    print("  âœ“ Purity levels (pure, mostly_pure, impure, unsafe)")
    print("  âœ“ SOLID design (Single Responsibility, Dependency Injection)")
    print("\nðŸŽ“ Phase 1 COMPLETE: All 3 weak properties enhanced!")
    print("  â€¢ complexity_class â†’ radon (compiler-grade)")
    print("  â€¢ function_contracts â†’ mypy (type-level)")
    print("  â€¢ side_effect_profile â†’ bandit (security-level)")
