ts,prompt_id,run_id,model,temperature,raw_output,code,canon_code,raw_hash,canon_signature,structural_ok,canonicalization_ok,contract_pass,oracle_pass,notes,attempts,last_error,status,metrics_version,contract_id
1756744207.0492055,anchor_fib_v1,anchor_fib_v1_1756744207,gpt-4o-mini,0.0,"```python
def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())
```","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)
    return [fib_recursive(i) for i in range(n)]
print(fibonacci())",05097966f6073032,9ad2e02da2b5b9c4,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744209.6112316,anchor_fib_v1,anchor_fib_v1_1756744209,gpt-4o-mini,0.0,"```python
def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())
```","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)
    return [fib_recursive(i) for i in range(n)]
print(fibonacci())",05097966f6073032,9ad2e02da2b5b9c4,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744213.653721,anchor_fib_v1,anchor_fib_v1_1756744213,gpt-4o-mini,0.0,"```python
def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())
```","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)
    return [fib_recursive(i) for i in range(n)]
print(fibonacci())",05097966f6073032,9ad2e02da2b5b9c4,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744215.8158195,anchor_fib_v1,anchor_fib_v1_1756744215,gpt-4o-mini,0.0,"```python
def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage:
# print(fibonacci())
```","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage:
# print(fibonacci())","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)
    return [fib_recursive(i) for i in range(n)]",cf757faccdab5a5a,149c1069397e3200,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744221.013734,anchor_fib_v1,anchor_fib_v1_1756744221,gpt-4o-mini,0.0,"```python
def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())
```","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)
    return [fib_recursive(i) for i in range(n)]
print(fibonacci())",05097966f6073032,9ad2e02da2b5b9c4,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744273.6973639,slugify_v1,slugify_v1_1756744273,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        text = text.lower().replace(' ', '-')
        return text

    return [slugify_text(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        text = text.lower().replace(' ', '-')
        return text

    return [slugify_text(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_text(text):
        text = unicodedata.normalize('NFKD', text)
        text = re.sub('[^\\w\\s-]', '', text)
        text = re.sub('\\s+', ' ', text).strip()
        text = text.lower().replace(' ', '-')
        return text
    return [slugify_text(text) for text in texts]",79998f15a93a1972,768e4953afc60d4f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744276.8404706,slugify_v1,slugify_v1_1756744276,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return text.lower().replace(' ', '-')
    
    return [slugify_text(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return text.lower().replace(' ', '-')
    
    return [slugify_text(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_text(text):
        text = unicodedata.normalize('NFKD', text)
        text = re.sub('[^\\w\\s-]', '', text)
        text = re.sub('\\s+', ' ', text).strip()
        return text.lower().replace(' ', '-')
    return [slugify_text(text) for text in texts]",52ab25c1068af8f2,61966c47cfd6af22,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744280.8088024,slugify_v1,slugify_v1_1756744280,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'\s+', '-', text.lower())
    
    return [slugify_text(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'\s+', '-', text.lower())
    
    return [slugify_text(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_text(text):
        text = unicodedata.normalize('NFKD', text)
        text = re.sub('[^\\w\\s-]', '', text)
        text = re.sub('\\s+', ' ', text).strip()
        return re.sub('\\s+', '-', text.lower())
    return [slugify_text(text) for text in texts]",cb58fadc09b526c9,d5746b78fbb38430,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744283.5571547,slugify_v1,slugify_v1_1756744283,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'[-\s]+', '-', text.lower())
    
    return [slugify_text(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'[-\s]+', '-', text.lower())
    
    return [slugify_text(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_text(text):
        text = unicodedata.normalize('NFKD', text)
        text = re.sub('[^\\w\\s-]', '', text)
        text = re.sub('\\s+', ' ', text).strip()
        return re.sub('[-\\s]+', '-', text.lower())
    return [slugify_text(text) for text in texts]",d83912cda6cfa43f,50a837613cde9c51,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744287.746713,slugify_v1,slugify_v1_1756744287,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'[-\s]+', '-', text.lower())
    
    return [slugify_text(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'[-\s]+', '-', text.lower())
    
    return [slugify_text(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_text(text):
        text = unicodedata.normalize('NFKD', text)
        text = re.sub('[^\\w\\s-]', '', text)
        text = re.sub('\\s+', ' ', text).strip()
        return re.sub('[-\\s]+', '-', text.lower())
    return [slugify_text(text) for text in texts]",d83912cda6cfa43f,50a837613cde9c51,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744345.817254,slugify_v2,slugify_v2_1756744345,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('\\s+', '-', no_diacritics.strip().lower())
        slug = re.sub('[^a-z0-9-]', '', slug)
        return slug
    return [normalize_and_slugify(text) for text in texts]",4f52894c4adeeb0d,dfc592cc1f9cf533,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744349.5427315,slugify_v2,slugify_v2_1756744349,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('\\s+', '-', no_diacritics.strip().lower())
        slug = re.sub('[^a-z0-9-]', '', slug)
        return slug
    return [normalize_and_slugify(text) for text in texts]",4f52894c4adeeb0d,dfc592cc1f9cf533,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744352.8383775,slugify_v2,slugify_v2_1756744352,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('\\s+', '-', no_diacritics.strip().lower())
        slug = re.sub('[^a-z0-9-]', '', slug)
        return slug
    return [normalize_and_slugify(text) for text in texts]",4f52894c4adeeb0d,dfc592cc1f9cf533,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744356.3109002,slugify_v2,slugify_v2_1756744356,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('\\s+', '-', no_diacritics.strip().lower())
        slug = re.sub('[^a-z0-9-]', '', slug)
        return slug
    return [normalize_and_slugify(text) for text in texts]",4f52894c4adeeb0d,dfc592cc1f9cf533,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744360.792203,slugify_v2,slugify_v2_1756744360,gpt-4o-mini,0.0,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('\\s+', '-', no_diacritics.strip().lower())
        slug = re.sub('[^a-z0-9-]', '', slug)
        return slug
    return [normalize_and_slugify(text) for text in texts]",4f52894c4adeeb0d,dfc592cc1f9cf533,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744409.6433773,csvjson_v1,csvjson_v1_1756744409,gpt-4o-mini,0.0,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    return result",df9e7900c2e3f3e3,27efb277124c588f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744411.5694497,csvjson_v1,csvjson_v1_1756744411,gpt-4o-mini,0.0,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    return result",df9e7900c2e3f3e3,27efb277124c588f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744414.3247178,csvjson_v1,csvjson_v1_1756744414,gpt-4o-mini,0.0,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    return result",df9e7900c2e3f3e3,27efb277124c588f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744417.4073331,csvjson_v1,csvjson_v1_1756744417,gpt-4o-mini,0.0,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    return result",df9e7900c2e3f3e3,27efb277124c588f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744420.9619749,csvjson_v1,csvjson_v1_1756744420,gpt-4o-mini,0.0,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    header = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {header[i]: values[i] for i in range(len(header))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    header = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {header[i]: values[i] for i in range(len(header))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    header = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {header[i]: values[i] for i in range(len(header))}
        result.append(entry)
    return result",55ff6860d2b9a2e5,04e8c77398dd1370,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744463.420224,csvjson_v2,csvjson_v2_1756744463,gpt-4o-mini,0.0,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744465.0338967,csvjson_v2,csvjson_v2_1756744465,gpt-4o-mini,0.0,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744466.8609023,csvjson_v2,csvjson_v2_1756744466,gpt-4o-mini,0.0,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744468.906951,csvjson_v2,csvjson_v2_1756744468,gpt-4o-mini,0.0,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744470.718825,csvjson_v2,csvjson_v2_1756744470,gpt-4o-mini,0.0,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744507.9110172,brackets_v1,brackets_v1_1756744507,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",96dae3f02a200e18,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744509.952319,brackets_v1,brackets_v1_1756744509,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",96dae3f02a200e18,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744511.9442747,brackets_v1,brackets_v1_1756744511,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",96dae3f02a200e18,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744514.5233815,brackets_v1,brackets_v1_1756744514,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",8b4b6e51b08ed4c1,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744517.2161117,brackets_v1,brackets_v1_1756744517,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",96dae3f02a200e18,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744559.9023752,brackets_v2,brackets_v2_1756744559,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    return len(stack) == 0",70c5e1b8cd6e0c3e,52301c9611327349,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
1756744562.1281402,brackets_v2,brackets_v2_1756744562,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    return len(stack) == 0",70c5e1b8cd6e0c3e,52301c9611327349,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
1756744564.4776797,brackets_v2,brackets_v2_1756744564,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    
    return len(stack) == 0","def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    return len(stack) == 0",65b0166e3e43f9db,93e13db610b6b8ef,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
1756744567.8872952,brackets_v2,brackets_v2_1756744567,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    
    return len(stack) == 0","def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    return len(stack) == 0",65b0166e3e43f9db,93e13db610b6b8ef,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
1756744570.7514362,brackets_v2,brackets_v2_1756744570,gpt-4o-mini,0.0,"```python
def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    return len(stack) == 0",70c5e1b8cd6e0c3e,52301c9611327349,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
