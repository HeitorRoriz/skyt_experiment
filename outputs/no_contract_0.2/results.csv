ts,prompt_id,run_id,model,temperature,raw_output,code,canon_code,raw_hash,canon_signature,structural_ok,canonicalization_ok,contract_pass,oracle_pass,notes,attempts,last_error,status,metrics_version,contract_id
1756744238.387733,anchor_fib_v1,anchor_fib_v1_1756744238,gpt-4o-mini,0.2,"```python
def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())
```","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)
    return [fib_recursive(i) for i in range(n)]
print(fibonacci())",05097966f6073032,9ad2e02da2b5b9c4,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744240.5519507,anchor_fib_v1,anchor_fib_v1_1756744240,gpt-4o-mini,0.2,"```python
def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())
```","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)
    return [fib_recursive(i) for i in range(n)]
print(fibonacci())",05097966f6073032,9ad2e02da2b5b9c4,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744245.833723,anchor_fib_v1,anchor_fib_v1_1756744245,gpt-4o-mini,0.2,"```python
def fibonacci(n, memo={0: 0, 1: 1}):
    if n not in memo:
        memo[n] = fibonacci(n - 1, memo) + fibonacci(n - 2, memo)
    return memo[n]

def generate_fibonacci_list(count):
    return [fibonacci(i) for i in range(count)]

def fibonacci():
    return generate_fibonacci_list(20)
```","def fibonacci(n, memo={0: 0, 1: 1}):
    if n not in memo:
        memo[n] = fibonacci(n - 1, memo) + fibonacci(n - 2, memo)
    return memo[n]

def generate_fibonacci_list(count):
    return [fibonacci(i) for i in range(count)]

def fibonacci():
    return generate_fibonacci_list(20)","def fibonacci(n, memo={0: 0, 1: 1}):
    if n not in memo:
        memo[n] = fibonacci(n - 1, memo) + fibonacci(n - 2, memo)
    return memo[n]
def generate_fibonacci_list(count):
    return [fibonacci(i) for i in range(count)]
def fibonacci():
    return generate_fibonacci_list(20)",5d0c40db7fc28a81,e1d6663e09ce3c68,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744247.9345732,anchor_fib_v1,anchor_fib_v1_1756744247,gpt-4o-mini,0.2,"```python
def fibonacci(n=20):
    def fib_helper(x):
        if x <= 1:
            return x
        else:
            return fib_helper(x - 1) + fib_helper(x - 2)

    return [fib_helper(i) for i in range(n)]

# Example usage
print(fibonacci())
```","def fibonacci(n=20):
    def fib_helper(x):
        if x <= 1:
            return x
        else:
            return fib_helper(x - 1) + fib_helper(x - 2)

    return [fib_helper(i) for i in range(n)]

# Example usage
print(fibonacci())","def fibonacci(n=20):
    def fib_helper(x):
        if x <= 1:
            return x
        else:
            return fib_helper(x - 1) + fib_helper(x - 2)
    return [fib_helper(i) for i in range(n)]
print(fibonacci())",7a6a9c2b4f391f4e,25f7db9d157caf33,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744250.5701702,anchor_fib_v1,anchor_fib_v1_1756744250,gpt-4o-mini,0.2,"```python
def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())
```","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)

    return [fib_recursive(i) for i in range(n)]

# Example usage
print(fibonacci())","def fibonacci(n=20):
    def fib_recursive(x):
        if x <= 1:
            return x
        else:
            return fib_recursive(x - 1) + fib_recursive(x - 2)
    return [fib_recursive(i) for i in range(n)]
print(fibonacci())",05097966f6073032,9ad2e02da2b5b9c4,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,anchor_fib_v1
1756744310.154487,slugify_v1,slugify_v1_1756744310,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def create_slug(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove unwanted characters and trim
        text = re.sub(r'[^\w\s-]', '', text).strip()
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'[-\s]+', '-', text)
        # Convert to lowercase
        return text.lower()
    
    return [create_slug(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def create_slug(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove unwanted characters and trim
        text = re.sub(r'[^\w\s-]', '', text).strip()
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'[-\s]+', '-', text)
        # Convert to lowercase
        return text.lower()
    
    return [create_slug(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def create_slug(text):
        text = unicodedata.normalize('NFKD', text)
        text = re.sub('[^\\w\\s-]', '', text).strip()
        text = re.sub('[-\\s]+', '-', text)
        return text.lower()
    return [create_slug(text) for text in texts]",88fc4bbda6d0115e,bcabd4ffd486a1a2,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744313.4556227,slugify_v1,slugify_v1_1756744313,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_single(text):
        # Normalize and remove accents
        text = unicodedata.normalize('NFKD', text)
        text = text.encode('ascii', 'ignore').decode('utf-8')
        # Trim and collapse whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Replace spaces with '-'
        text = text.lower().replace(' ', '-')
        # Keep only letters, numbers, and '-'
        text = re.sub(r'[^a-z0-9-]', '', text)
        return text
    
    return [slugify_single(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_single(text):
        # Normalize and remove accents
        text = unicodedata.normalize('NFKD', text)
        text = text.encode('ascii', 'ignore').decode('utf-8')
        # Trim and collapse whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Replace spaces with '-'
        text = text.lower().replace(' ', '-')
        # Keep only letters, numbers, and '-'
        text = re.sub(r'[^a-z0-9-]', '', text)
        return text
    
    return [slugify_single(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_single(text):
        text = unicodedata.normalize('NFKD', text)
        text = text.encode('ascii', 'ignore').decode('utf-8')
        text = re.sub('\\s+', ' ', text).strip()
        text = text.lower().replace(' ', '-')
        text = re.sub('[^a-z0-9-]', '', text)
        return text
    return [slugify_single(text) for text in texts]",2eaeb08788aa5031,628f4cb9bfacc1c0,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744316.382118,slugify_v1,slugify_v1_1756744316,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_single(text):
        # Normalize and remove accents
        text = unicodedata.normalize('NFKD', text)
        text = text.encode('ascii', 'ignore').decode('utf-8')
        # Trim, collapse whitespace, and convert to lowercase
        text = re.sub(r'\s+', ' ', text).strip().lower()
        # Replace spaces with '-' and keep only valid characters
        text = re.sub(r'[^a-z0-9 -]', '', text)
        text = text.replace(' ', '-')
        return text

    return [slugify_single(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_single(text):
        # Normalize and remove accents
        text = unicodedata.normalize('NFKD', text)
        text = text.encode('ascii', 'ignore').decode('utf-8')
        # Trim, collapse whitespace, and convert to lowercase
        text = re.sub(r'\s+', ' ', text).strip().lower()
        # Replace spaces with '-' and keep only valid characters
        text = re.sub(r'[^a-z0-9 -]', '', text)
        text = text.replace(' ', '-')
        return text

    return [slugify_single(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_single(text):
        text = unicodedata.normalize('NFKD', text)
        text = text.encode('ascii', 'ignore').decode('utf-8')
        text = re.sub('\\s+', ' ', text).strip().lower()
        text = re.sub('[^a-z0-9 -]', '', text)
        text = text.replace(' ', '-')
        return text
    return [slugify_single(text) for text in texts]",fcd984902f5c17e2,460a64b1c147fc67,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744319.7310488,slugify_v1,slugify_v1_1756744319,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'\s+', '-', text.lower())
    
    return [slugify_text(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse internal whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'\s+', '-', text.lower())
    
    return [slugify_text(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_text(text):
        text = unicodedata.normalize('NFKD', text)
        text = re.sub('[^\\w\\s-]', '', text)
        text = re.sub('\\s+', ' ', text).strip()
        return re.sub('\\s+', '-', text.lower())
    return [slugify_text(text) for text in texts]",cb58fadc09b526c9,d5746b78fbb38430,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744323.941729,slugify_v1,slugify_v1_1756744323,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'[-\s]+', '-', text.lower())

    return [slugify_text(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def slugify_text(text):
        # Normalize the text to remove accents
        text = unicodedata.normalize('NFKD', text)
        # Remove non-ASCII characters
        text = re.sub(r'[^\w\s-]', '', text)
        # Replace spaces and collapse whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        # Convert to lowercase and replace spaces with '-'
        return re.sub(r'[-\s]+', '-', text.lower())

    return [slugify_text(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def slugify_text(text):
        text = unicodedata.normalize('NFKD', text)
        text = re.sub('[^\\w\\s-]', '', text)
        text = re.sub('\\s+', ' ', text).strip()
        return re.sub('[-\\s]+', '-', text.lower())
    return [slugify_text(text) for text in texts]",9e15c2f1e9b289a5,50a837613cde9c51,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v1
1756744379.301679,slugify_v2,slugify_v2_1756744379,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD and remove accents
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD and remove accents
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('\\s+', '-', no_diacritics.strip().lower())
        slug = re.sub('[^a-z0-9-]', '', slug)
        return slug
    return [normalize_and_slugify(text) for text in texts]",b64cab59af6f2a7c,dfc592cc1f9cf533,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744382.8053489,slugify_v2,slugify_v2_1756744382,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        text = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        text = re.sub(r'\s+', '-', text.strip().lower())
        # Remove characters not in [a-z0-9-]
        text = re.sub(r'[^a-z0-9-]', '', text)
        return text

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        text = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        text = re.sub(r'\s+', '-', text.strip().lower())
        # Remove characters not in [a-z0-9-]
        text = re.sub(r'[^a-z0-9-]', '', text)
        return text

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        text = unicodedata.normalize('NFKD', text)
        text = ''.join((c for c in text if unicodedata.category(c) != 'Mn'))
        text = re.sub('\\s+', '-', text.strip().lower())
        text = re.sub('[^a-z0-9-]', '', text)
        return text
    return [normalize_and_slugify(text) for text in texts]",72c3a731519ea1ed,e306dbaece24865e,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744387.6844697,slugify_v2,slugify_v2_1756744387,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        return slug

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('\\s+', '-', no_diacritics.strip().lower())
        slug = re.sub('[^a-z0-9-]', '', slug)
        return slug
    return [normalize_and_slugify(text) for text in texts]",4f52894c4adeeb0d,dfc592cc1f9cf533,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744391.418761,slugify_v2,slugify_v2_1756744391,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    slugs = []
    for text in texts:
        # Normalize and remove accents
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        slugs.append(slug)
    return slugs
```","import unicodedata
import re

def slugify(texts):
    slugs = []
    for text in texts:
        # Normalize and remove accents
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, and replace spaces with '-'
        slug = re.sub(r'\s+', '-', no_diacritics.strip().lower())
        # Remove characters not in [a-z0-9-]
        slug = re.sub(r'[^a-z0-9-]', '', slug)
        slugs.append(slug)
    return slugs","import unicodedata
import re
def slugify(texts):
    slugs = []
    for text in texts:
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('\\s+', '-', no_diacritics.strip().lower())
        slug = re.sub('[^a-z0-9-]', '', slug)
        slugs.append(slug)
    return slugs",6d54c7641e384063,e7e0da8e08e9c010,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744395.3876781,slugify_v2,slugify_v2_1756744395,gpt-4o-mini,0.2,"```python
import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, replace spaces with '-', and remove unwanted characters
        slug = re.sub(r'[^a-zA-Z0-9\s-]', '', no_diacritics)
        slug = re.sub(r'\s+', '-', slug.strip().lower())
        return slug

    return [normalize_and_slugify(text) for text in texts]
```","import unicodedata
import re

def slugify(texts):
    def normalize_and_slugify(text):
        # Normalize to NFKD
        normalized = unicodedata.normalize('NFKD', text)
        # Remove diacritics
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        # Strip, collapse spaces, lower, replace spaces with '-', and remove unwanted characters
        slug = re.sub(r'[^a-zA-Z0-9\s-]', '', no_diacritics)
        slug = re.sub(r'\s+', '-', slug.strip().lower())
        return slug

    return [normalize_and_slugify(text) for text in texts]","import unicodedata
import re
def slugify(texts):
    def normalize_and_slugify(text):
        normalized = unicodedata.normalize('NFKD', text)
        no_diacritics = normalized.encode('ascii', 'ignore').decode('utf-8')
        slug = re.sub('[^a-zA-Z0-9\\s-]', '', no_diacritics)
        slug = re.sub('\\s+', '-', slug.strip().lower())
        return slug
    return [normalize_and_slugify(text) for text in texts]",bd48c5f2309cbc2a,ba75a1219896b3cd,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,slugify_v2
1756744435.2665024,csvjson_v1,csvjson_v1_1756744435,gpt-4o-mini,0.2,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    return result",df9e7900c2e3f3e3,27efb277124c588f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744437.2477171,csvjson_v1,csvjson_v1_1756744437,gpt-4o-mini,0.2,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    return result",df9e7900c2e3f3e3,27efb277124c588f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744440.4932694,csvjson_v1,csvjson_v1_1756744440,gpt-4o-mini,0.2,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    header = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {header[i]: values[i] for i in range(len(header))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    header = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {header[i]: values[i] for i in range(len(header))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    header = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {header[i]: values[i] for i in range(len(header))}
        result.append(entry)
    return result",55ff6860d2b9a2e5,04e8c77398dd1370,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744443.548322,csvjson_v1,csvjson_v1_1756744443,gpt-4o-mini,0.2,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    return result",df9e7900c2e3f3e3,27efb277124c588f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744446.4607038,csvjson_v1,csvjson_v1_1756744446,gpt-4o-mini,0.2,"```python
def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result
```","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    
    return result","def csv_to_json(csv_text):
    lines = csv_text.strip().split('\n')
    headers = lines[0].split(',')
    result = []
    for line in lines[1:]:
        values = line.split(',')
        entry = {headers[i]: values[i] for i in range(len(headers))}
        result.append(entry)
    return result",df9e7900c2e3f3e3,27efb277124c588f,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v1
1756744487.0249689,csvjson_v2,csvjson_v2_1756744487,gpt-4o-mini,0.2,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744489.0883152,csvjson_v2,csvjson_v2_1756744489,gpt-4o-mini,0.2,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744490.8973975,csvjson_v2,csvjson_v2_1756744490,gpt-4o-mini,0.2,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744492.818834,csvjson_v2,csvjson_v2_1756744492,gpt-4o-mini,0.2,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744494.348942,csvjson_v2,csvjson_v2_1756744494,gpt-4o-mini,0.2,"```python
import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]
```","import csv
import json
from typing import List, Dict

def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]","import csv
import json
from typing import List, Dict
def csv_to_json(csv_text: str) -> List[Dict[str, str]]:
    reader = csv.DictReader(csv_text.splitlines())
    return [row for row in reader]",13e4ddc58edbff5d,b38f3891ccff4945,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,csvjson_v2
1756744532.0474157,brackets_v1,brackets_v1_1756744532,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
                
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
                
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",c9606186035f84d1,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744534.256246,brackets_v1,brackets_v1_1756744534,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",8b4b6e51b08ed4c1,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744536.5049381,brackets_v1,brackets_v1_1756744536,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",8b4b6e51b08ed4c1,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744538.3029447,brackets_v1,brackets_v1_1756744538,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",8b4b6e51b08ed4c1,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744541.0216508,brackets_v1,brackets_v1_1756744541,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
                
    return not stack
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
                
    return not stack","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return not stack",c9606186035f84d1,08d608547462d16a,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v1
1756744586.0627317,brackets_v2,brackets_v2_1756744586,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    
    return len(stack) == 0","def is_balanced(s):
    stack = []
    parentheses_map = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in parentheses_map.values():
            stack.append(char)
        elif char in parentheses_map.keys():
            if not stack or stack.pop() != parentheses_map[char]:
                return False
    return len(stack) == 0",65b0166e3e43f9db,93e13db610b6b8ef,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
1756744588.236519,brackets_v2,brackets_v2_1756744588,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    return len(stack) == 0",70c5e1b8cd6e0c3e,52301c9611327349,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
1756744590.663842,brackets_v2,brackets_v2_1756744590,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    mapping = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in mapping.values():
            stack.append(char)
        elif char in mapping.keys():
            if stack == [] or mapping[char] != stack.pop():
                return False
                
    return stack == []
```","def is_balanced(s):
    stack = []
    mapping = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in mapping.values():
            stack.append(char)
        elif char in mapping.keys():
            if stack == [] or mapping[char] != stack.pop():
                return False
                
    return stack == []","def is_balanced(s):
    stack = []
    mapping = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in mapping.values():
            stack.append(char)
        elif char in mapping.keys():
            if stack == [] or mapping[char] != stack.pop():
                return False
    return stack == []",77499b4a10d64747,7c5f6b84f40605e0,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
1756744594.0206103,brackets_v2,brackets_v2_1756744594,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
                
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
                
    return len(stack) == 0","def is_balanced(s):
    stack = []
    brackets = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in brackets.values():
            stack.append(char)
        elif char in brackets.keys():
            if not stack or stack.pop() != brackets[char]:
                return False
    return len(stack) == 0",bf0bda784d8abe8f,575ed40b22d69af4,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
1756744596.1634836,brackets_v2,brackets_v2_1756744596,gpt-4o-mini,0.2,"```python
def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0
```","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    
    return len(stack) == 0","def is_balanced(s):
    stack = []
    parentheses = {')': '(', ']': '[', '}': '{'}
    for char in s:
        if char in parentheses.values():
            stack.append(char)
        elif char in parentheses.keys():
            if not stack or stack.pop() != parentheses[char]:
                return False
    return len(stack) == 0",70c5e1b8cd6e0c3e,52301c9611327349,True,True,True,True,stripped_fences; stripped_docstrings; normalized_identifiers; stripped_comments; normalized_whitespace,1,,completed,2025-08-26,brackets_v2
